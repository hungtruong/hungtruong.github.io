WEBVTT

00:00:00.000 --> 00:00:03.676
Introducing BarkMode: Bark Detection + Dark Mode

00:00:05.176 --> 00:00:07.573
Published on July 14, 2019.

00:00:08.573 --> 00:00:14.407
I was in California about a month ago for work and I was able to attend a few events during WWDC week.

00:00:14.907 --> 00:00:26.974
I read a lot about the new features and APIs but didnâ€™t really have a lot of time to mess with stuff like SwiftUI, etc. I got a stupid idea for a project but I didnâ€™t really take the time to work on it until this weekend.

00:00:27.474 --> 00:00:30.751
Now Iâ€™d like to introduce you to my latest app: Bark Mode!

00:00:31.751 --> 00:00:34.148
WTF is Bark Mode?

00:00:35.648 --> 00:00:41.961
Right after the new APIs were announced at WWDC, I scanned them for anything that might be interesting.

00:00:42.461 --> 00:00:49.654
I really like being one of the first to try out a new technology, but I figured that everyone would be all over SwiftUI , and I was right.

00:00:50.154 --> 00:00:57.346
I found a somewhat obscure new feature as part of CreateML that allowed users to generate a ML model that could classify sounds.

00:00:58.346 --> 00:01:04.259
This SoundAnalysis API in particular seems relevant to my typically immature interests.

00:01:04.759 --> 00:01:15.948
ðŸ’¨ #WWDC19 https://t.co/0Aipwa99Lu â€” Hung Truong (@hungtruong) June 4, 2019

00:01:16.948 --> 00:01:21.103
Of course the first thing I thought of was to make an app that could detect farts.

00:01:21.603 --> 00:01:25.279
I could even make it so that a fart would toggle dark mode off/on.

00:01:25.779 --> 00:01:43.518
Though I wanted to start experimenting right away, I discovered that you actually needed to have the newest version of macOS Catalina installed in addition to the newest Xcode to use Create ML, and I didnâ€™t have my personal computer handy and couldnâ€™t install a beta OS on my work computer, so I ended up not building it.

00:01:44.518 --> 00:01:51.231
Fast forward to this weekend, and I eventually got Catalina and all the other prerequisites I needed to get started.

00:01:51.731 --> 00:02:00.361
Instead of â€œFarkModeâ€ which doesnâ€™t really make sense, I decided to switch it up this time and detect dogs barking, since â€œBarkâ€ rhymes better with â€œDarkâ€ than â€œFart.â€

00:02:00.861 --> 00:02:03.259
Plus everybody loves dogs!

00:02:03.759 --> 00:02:07.674
Perhaps Iâ€™m finally maturing in my old age (probably not).

00:02:08.674 --> 00:02:11.951
Anyway, hereâ€™s the steps I needed to take to make my BarkMode app.

00:02:12.951 --> 00:02:14.549
Creating the model

00:02:16.049 --> 00:02:21.003
I had seen some videos of people making image classifiers using CreateML in the past.

00:02:21.503 --> 00:02:26.618
It seemed as easy as creating a few folders with different labels and images of those things.

00:02:27.118 --> 00:02:33.191
You would have to create one batch for training images, and another for optionally testing the models once they were created.

00:02:34.191 --> 00:02:40.744
The process for creating an audio classifier is pretty similar except that you need to use sound files instead of images.

00:02:41.244 --> 00:02:45.000
I started by finding a bunch of stock sound effects of dogs barking.

00:02:45.500 --> 00:02:52.452
I also found a bunch of random stock sound effects of things like bells ringing, wind blowing, and other stuff that I could label as â€œnot barking.â€

00:02:52.952 --> 00:03:01.583
I feel like this is a pretty wacky way to do classification but if thereâ€™s another way that doesnâ€™t involve downloading a bunch of random stock sound effects, that would be awesome.

00:03:02.583 --> 00:03:06.499
At first I took larger sound files and chopped them up into really short ones.

00:03:06.999 --> 00:03:12.353
This way I had a bunch of training data that I can use both to train and test my classifier.

00:03:13.353 --> 00:03:20.066
However, when I ran the Create ML app on the training data, I got an obscure error that the training had been interrupted.

00:03:20.566 --> 00:03:24.801
I saw that the app thought I only had 3 files when I had created a bunch more.

00:03:25.301 --> 00:03:30.735
I believe that Create ML is unable to train with really short audio files (less than a second).

00:03:31.235 --> 00:03:35.470
I ended up inserting the full sound files instead of the short ones.

00:03:35.970 --> 00:03:41.245
At this point I think I had about 8 or 9 files for either barking or not barking.

00:03:42.245 --> 00:03:46.800
The model was created but it had a really terrible accuracy.

00:03:47.300 --> 00:03:52.893
I decided to just add a bunch more files both of dogs barking and things that werenâ€™t dogs barking.

00:03:53.393 --> 00:03:56.830
The more examples I added the â€œbetterâ€ the model became.

00:03:57.830 --> 00:03:59.188
Polishing the model

00:04:00.688 --> 00:04:07.081
Create ML has a feature where you can test your audio classifier with audio data coming from your own microphone.

00:04:07.581 --> 00:04:12.536
When I did this I noticed that the model was too biased towards no sound being barking.

00:04:13.036 --> 00:04:18.070
Iâ€™m not sure why but maybe white noise sounds more like barking than an old timey car horn?

00:04:19.070 --> 00:04:23.146
I ended up adding a bunch of white noise and recorded some nothing to add to the model.

00:04:23.646 --> 00:04:25.244
This helped quite a bit.

00:04:25.744 --> 00:04:32.137
The last thing I did was also record some audio of myself talking so that the model would not recognize me talking as barking.

00:04:32.637 --> 00:04:39.829
This was useful so I wouldnâ€™t get false positives during my demo video (which I ended up getting anyway in a bunch of outtakes).

00:04:40.829 --> 00:04:43.067
Integrating the model in the app

00:04:44.567 --> 00:04:48.242
I created a new app and promptly enabled â€œUse SwiftUI.â€

00:04:48.742 --> 00:04:53.217
Then I promptly made a new project because I couldnâ€™t figure out where my ViewController class was!

00:04:53.717 --> 00:04:59.631
Iâ€™ll take a look at SwiftUI later but for now Iâ€™ll focus on getting my BarkMode app actually working.

00:05:00.631 --> 00:05:04.147
The Create ML app made a model that I could then copy into my app.

00:05:04.647 --> 00:05:08.643
It was really as simple as dragging it from one place to another.

00:05:09.643 --> 00:05:18.433
Looking at the model in Xcode, it describes an interface with an input of â€œaudioSamplesâ€ that takes a MultiArray of (Float32 15600).

00:05:18.933 --> 00:05:23.728
I assumed this had something to do with the number of samples per second and the bitrate of the audio.

00:05:24.228 --> 00:05:36.536
I fiddled around with the AudioToolbox framework and a few other lower level audio APIs until I discovered Appleâ€™s documentation on the SoundAnalysis framework which provides a much, much easier method of feeding audio to the model.

00:05:37.536 --> 00:05:42.730
I implemented the steps described and extended my ViewController to conform to the SNResultsObserving protocol.

00:05:43.230 --> 00:05:52.900
Then it was a few simple steps to write some logic to handle the app detecting no barking to barking and back to no barking, and toggling the dark mode off and on.

00:05:53.900 --> 00:06:02.451
Finally, I added a label and an image view that takes an image with different assets for the light and dark modes, which changes automatically based on the current setting.

00:06:03.451 --> 00:06:05.209
The model runs pretty quickly.

00:06:05.709 --> 00:06:10.983
Hereâ€™s a gif of the terminal output from the logging whenever some sound data comes in:

00:06:11.983 --> 00:06:15.579
If you want to see the app in action, I created this video to demonstrate:

00:06:16.579 --> 00:06:23.771
As it is, this app isnâ€™t very useful for much of anything, but I could see a few potential uses for the model I trained:

00:06:24.771 --> 00:06:32.363
Write an app that detects your dog is unhappy when itâ€™s at home and triggers a home automation action like playing music or shooting a treat at your dog

00:06:33.363 --> 00:06:37.838
Detect if suspicious sound at your house is a robber or just a dog

00:06:38.838 --> 00:06:43.073
Classify different types of barks and make a dog barking translation app

00:06:44.073 --> 00:06:48.149
For people who are allergic to dogs, advance warning of incoming dog

00:06:49.149 --> 00:06:54.023
Iâ€™ve posted the full project to Github in case youâ€™re curious about how I implemented the app.

00:06:54.523 --> 00:07:00.757
I didnâ€™t upload the Create ML project but it just has a bunch of sound effect files and files of me saying gibberish.

00:07:01.257 --> 00:07:05.412
The model included in the Github repo should work fine anyway.

00:07:06.412 --> 00:07:08.170
Iâ€™m pretty happy with my end result.

00:07:08.670 --> 00:07:16.741
Itâ€™s fun to play around with new APIs and now I can say that Iâ€™ve trained an ML model to classify sounds, in addition to implementing Dark Mode!

00:07:17.241 --> 00:07:21.557
Hopefully Iâ€™ll have some time to play with other APIs that were introduced to iOS soon.
